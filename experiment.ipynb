{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 12:56:53.178777: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-09 12:56:53.492943: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-09 12:56:54.588551: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-09 12:56:54.588604: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-09 12:56:54.588608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TapasForQuestionAnswering\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
    "\n",
    "model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TapasForQuestionAnswering(\n",
       "  (tapas): TapasModel(\n",
       "    (embeddings): TapasEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(1024, 768)\n",
       "      (token_type_embeddings_0): Embedding(3, 768)\n",
       "      (token_type_embeddings_1): Embedding(256, 768)\n",
       "      (token_type_embeddings_2): Embedding(256, 768)\n",
       "      (token_type_embeddings_3): Embedding(2, 768)\n",
       "      (token_type_embeddings_4): Embedding(256, 768)\n",
       "      (token_type_embeddings_5): Embedding(256, 768)\n",
       "      (token_type_embeddings_6): Embedding(10, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TapasEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): TapasPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (aggregation_classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TapasForQuestionAnswering\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
    "\n",
    "data = {\n",
    "\n",
    "    \"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"],\n",
    "\n",
    "    \"Age\": [\"56\", \"45\", \"59\"],\n",
    "\n",
    "    \"Number of movies\": [\"87\", \"53\", \"69\"],\n",
    "\n",
    "}\n",
    "\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "\n",
    "queries = [\"How many movies has George Clooney played in?\", \"How old is Brad Pitt?\"]\n",
    "\n",
    "inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'neuron'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_neuron \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mneuron\u001b[39m.\u001b[39mtrace(model, inputs, compiler_args\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m-O2\u001b[39m\u001b[39m'\u001b[39m], verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, compiler_workdir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./compile\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m# Save the TorchScript for later use\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_neuron\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mintent_neuron.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'neuron'"
     ]
    }
   ],
   "source": [
    "model_neuron = torch.neuron.trace(model, inputs, compiler_args=['-O2'], verbose=1, compiler_workdir='./compile')# Save the TorchScript for later use\n",
    "model_neuron.save('intent_neuron.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logits = outputs.logits\n",
    "\n",
    "logits_aggregation = outputs.logits_aggregation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
